# KDF日志分析平台架构设计说明书【V1.0.0】

[TOC]



## 1、文档介绍

### 1.1、文档目的

- 设计大数据集成日志分析平台（以下简称“日志分析平台”），是对各互联网应用的日志信息进行访问、采集、解析、清洗、转换，同时可以编写模型支持后台统计分析算法。
- 设计日志信息可视化平台（以下简称“可视化平台”），应用于日志信息的可视化和互动操作。
- 为此，根据“先进实用，稳定可靠”的原则设计本日志分析平台及可视化平台。

### 1.2、文档范围

- 包括日志数据的处理包括ETL、分析、可视化和使用。

### 1.3、读者对象

- 管理人员
- 开发人员

### 1.4、参考文献

- 《CSDN博客》等

### 1.5、术语与缩写解释

| 术语、缩写 | 解释                                                         |
| ---------- | ------------------------------------------------------------ |
| ETL        | ETL是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程。 |
| Nginx      | 高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务 |
| Flume      | Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统 |
| HDFS       | Hadoop分布式文件系统                                         |
| Hbase      | 分布式的、面向列的开源数据库                                 |
| Hive       | Hadoop的一个数据仓库工具                                     |
| Mysql      | 关系型数据库管理系统                                         |
## 2、系统概述

- 日志分析平台分为3个层次，主要功能是对互联网应用的日志信息进行访问，采集，解析，清洗，整合，ETL，同时编写模型支持可视化平台统计分析算法，提供可信的数据。
- 可视化平台分为3个层次，在日志分析平台的基础上实现数据的可视化和互动操作。

## 3、系统约束

- 系统必须遵循国家软件开发的标准。
- 系统用java开发，采用开源的中间件。
- 系统必须稳定可靠，性能高，满足每天千万次的访问。
- 保证数据的成功抽取、转换、分析，实现高可信和高可用。

## 4、设计策略

- 系统高可用、高性能、易扩展，安全稳定，实用可靠，满足用户的需要。
- 系统可以进行扩展，增加数据的种类和数量。
- 系统可以复用别的软件和算法。

## 5、系统总体架构

### 5.1、逻辑架构

![逻辑架构](https://coding-net-production-file-ci.codehub.cn/544ce340-ee20-11e9-a4c6-09de8ec96834.jpg?sign=1iUG1h6K4M+FW52dUF2Di8uU/gZhPTEyNTcyNDI1OTkmaz1BS0lEYXk4M2xGbWFTNlk0TFRkek1WTzFTZFpPeUpTTk9ZcHImZT0xNTcxMjMxODkwJnQ9MTU3MTAxNTg5MCZyPTg3NjA2NDE4JmY9LzU0NGNlMzQwLWVlMjAtMTFlOS1hNGM2LTA5ZGU4ZWM5NjgzNC5qcGcmYj1jb2RpbmctbmV0LXByb2R1Y3Rpb24tZmlsZQ== "逻辑架构")

### 5.2、架构说明

1. **数据源：**通过HTTPClient以javajar的方式注入至企业应用服务器中，获取互联网应用服务器的接口日志信息，或者通过Ajax以jsapi的方式获取互联网的网页的埋点业务信息，定制日志信息的格式对获取的日志信息进行拦截，获取有效的日志信息。

2. **数据获取层：**nginx代理服务器接收数据源的数据，nginx服务器定时将生成的日志文件拆分成多个，并保存至本地，配置日志文件清理策略，定时清理已完成的日志文件。

3. **数据导入层：**通过的flume的source，以dirpool的方式实时扫描nginx的日志文件夹，将未处理的日志文件经过channel的缓存通过sink发送至HDFS；channel可以为本地内存（memory），也可以使用kafka对发送的缓存文件进行本地化存储，保证发送文件的安全性。

4. **数据抽取层：**对导入的数据进行抽取、清洗、整理，并存入核心存储层。

5. **数据核心存储层：**采用hbase，关系数据库保存抽取后的数据。

6. **数据分析层：**定时查询hbase中的数据，对数据进行进一步分析、整理，最后通过Hive生成结构化的数据存储结构。

7. **数据获取层：**获取结构化的数据，建立与之关联的模型，并保存至Mysql。

8. **服务层：**对数据进行分析统计、数据挖掘。

9. **应用层：**生成报表、图表。

### 5.3、系统特点

1. 系统采用一系列先进的开源技术框架，实现大数据的抽取、ETL转换、清洗、整合、汇总、统计分析，得出可信度高的结果，高速稳定地响应用户的请求，可对公司的宽系列产品提供高质量的支持。

2. **高负载和海量存储能力：**以云存储或本地存储为基石，以云计算或企业服务器为处理核心，建立了海量的数据业务支持的日志处理平台。

3. **实时性：**可以对各项业务数据实时查看与统计，方便通过数据做出及时的决策和反馈。

4. **统一数据接入平台：**数据接入层采用flume、分布式日志系统，实现推拉模式的各种主流方式，可以实现各类接口的无缝接入。

5. **可靠性：**以云平台作为支撑。更平台有极强的可靠性，保证稳定、有效、安全的运行。

6. **可扩展性：**以云平台作为支撑。可实现各类平台组件按需横向扩展，如存储扩展、计算增强等。

7. **集成性：**丰富的接口具有极强的集成性。可以实现与企业内部系统的高密度集成，根据不同业务调取日志和日志分析结果。

8. **可视化强：**统计数据以图表、热图等方式体现，方便对比判断。

9. **提供定制服务：**可以根据特定需求进行丰富的功能扩展，量身定制实用的日志分析平台。

## 6、其他